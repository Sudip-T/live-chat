{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d4056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "url = 'https://www.nepalyp.com/browse-business-directory'\n",
    "response = requests.get(url)\n",
    "soup = bs(response.content, 'html.parser')\n",
    "\n",
    "content = soup.find('main')\n",
    "\n",
    "def fetch_page(url):\n",
    "    response = requests.get(url)\n",
    "    return bs(response.content, 'html.parser')\n",
    "\n",
    "def fetch_company_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        page_soup = bs(response.content, 'html.parser')\n",
    "        company_item_div = page_soup.find('div', {'id': 'company_item'})\n",
    "        company_data = {}\n",
    "        \n",
    "        if company_item_div:\n",
    "            company_data['name'] = company_item_div.find('b', id='company_name').text.strip()\n",
    "            company_data['location'] = company_item_div.find('div', {'class': 'text location'}).text.strip()\n",
    "            company_data['website'] = company_item_div.find('div', {'class': 'text weblinks'}).text if company_item_div.find('div', {'class': 'weblinks'}) else 'NaN'\n",
    "\n",
    "            # Extract contact numbers\n",
    "            contact = company_item_div.find('div', class_='text phone')\n",
    "            if contact:\n",
    "                contact_numbers = [contact.strip() for contact in contact.get_text(separator='\\n').split('\\n') if contact.strip()]\n",
    "                contact_numbers_str = \", \".join(contact_numbers)\n",
    "            else:\n",
    "                contact_numbers_str = 'NaN'\n",
    "            company_data['contact_numbers'] = contact_numbers_str\n",
    "\n",
    "            # Extract map coordinates\n",
    "            map_canvas_div = company_item_div.find('div', id='map_canvas')\n",
    "            if map_canvas_div:\n",
    "                data_map_ltd = map_canvas_div.get('data-map-ltd')\n",
    "                data_map_lng = map_canvas_div.get('data-map-lng')\n",
    "                map_coordinates = f'{data_map_ltd},{data_map_lng}'\n",
    "            else:\n",
    "                map_coordinates = 'NaN'\n",
    "            company_data['map_coordinates'] = map_coordinates\n",
    "\n",
    "            # Extract mobile numbers\n",
    "            label_div = company_item_div.find('div', class_='label', text='Mobile phone')\n",
    "            if label_div:\n",
    "                text_div = label_div.find_next_sibling('div', class_='text')\n",
    "                mobile_numbers = [number.strip() for number in text_div.get_text(separator='\\n').split('\\n') if number.strip()]\n",
    "                mobile_numbers_str = \", \".join(mobile_numbers)\n",
    "            else:\n",
    "                mobile_numbers_str = 'NaN'\n",
    "            company_data['Mobile Numbers'] = mobile_numbers_str\n",
    "        \n",
    "        return company_data\n",
    "    return None\n",
    "\n",
    "def fetch_data(url):\n",
    "    data_list = []\n",
    "    while url:\n",
    "        soup = fetch_page(url)\n",
    "        listings = soup.find('div', attrs={'id': 'listings'})\n",
    "        \n",
    "        company_links = ['https://www.nepalyp.com{}'.format(row.find('h4').a['href']) for row in listings.select('div.company:not(.company_ad)')]\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            future_to_url = {executor.submit(fetch_company_data, link): link for link in company_links}\n",
    "            for future in tqdm(as_completed(future_to_url), total=len(company_links), desc=\"Fetching company data\"):\n",
    "                data_list.append(future.result())\n",
    "        \n",
    "        next_link = soup.find('div', class_='pages_container')\n",
    "        try:\n",
    "            next_link = next_link.find('a', class_='pages_arrow', rel='next')\n",
    "        except:\n",
    "            next_link = None\n",
    "        url = 'https://www.nepalyp.com{}'.format(next_link['href']) if next_link else None\n",
    "\n",
    "    return data_list\n",
    "\n",
    "category_data = []\n",
    "\n",
    "for category in tqdm(content.find_all('h2', class_='cath2'), desc=\"Fetching categories\"):\n",
    "    category_name = category.text.strip()\n",
    "    category_dict = {\"category\": category_name, \"subcategories\": []}\n",
    "    \n",
    "    for li in tqdm(category.find_next_sibling('ul', class_='cat_list').find_all('li'), desc=f\"Fetching subcategories for {category_name}\"):\n",
    "        subcategory_name = [subcategory.strip() for subcategory in li.get_text(separator='\\n').split('\\n') if subcategory.strip()][0]\n",
    "        a_href = li.a['href'] if li.a else 'NaN'\n",
    "        category_dict[\"subcategories\"].append({subcategory_name: []})\n",
    "        if a_href != 'NaN':\n",
    "            url = f'https://www.nepalyp.com{a_href}'\n",
    "            category_dict['subcategories'][-1][subcategory_name] = fetch_data(url)\n",
    "        # break\n",
    "    category_data.append(category_dict)\n",
    "    # break\n",
    "\n",
    "# Save the data to a file or use it as needed\n",
    "df = pd.DataFrame(category_data)\n",
    "df.to_csv('business_data.csv', index=False)\n",
    "# Assuming category_data is your data\n",
    "df = pd.DataFrame(category_data)\n",
    "\n",
    "# Save DataFrame as JSON\n",
    "df.to_json('business_data.json', orient='records', lines=True, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
